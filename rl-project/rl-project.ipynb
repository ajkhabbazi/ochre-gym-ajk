{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ade1e1b6-01c8-4bf0-8530-8807bb5026d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A price lookahead of 15 mins is less than or is  not a multiple of the control interval 30 mins.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mochre_gym\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# 1) Load env with only heating setpoint control\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mochre_gym\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbasic-v0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverride_equipment_controls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHVAC Heating\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSetpoint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvectorize_actions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvectorize_observations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Small, stable observation set (edit to taste)\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverride_ochre_observations_with_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTemperature - Indoor (C)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTemperature - Outdoor (C)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEnergy Price ($)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHour of Day\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# provided by env if supported; else encode from Datetime in wrapper\u001b[39;49;00m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2018-12-01 00:00:00\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2018-12-31 23:30:00\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_res\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m00:30\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdr_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRTP\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreward_normalization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthermal_comfort_band\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m20.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m23.0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthermal_comfort_unit_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_to_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_to_console\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# 2) Discretize the heating setpoint (e.g., 7 actions from 20.0 to 23.0 by 0.5C)\u001b[39;00m\n\u001b[0;32m     29\u001b[0m SETPOINTS \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m20.0\u001b[39m, \u001b[38;5;241m23.0\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;241m0.5\u001b[39m), \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# [20.0, 20.5, ..., 23.0]\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\ochre-gym-env\\lib\\site-packages\\ochre_gym\\__init__.py:194\u001b[0m, in \u001b[0;36mload\u001b[1;34m(env_name, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m     logger \u001b[38;5;241m=\u001b[39m log\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m, handler_types\u001b[38;5;241m=\u001b[39mhandler_types, log_file \u001b[38;5;241m=\u001b[39m log_output)\n\u001b[0;32m    191\u001b[0m \u001b[38;5;66;03m##################################\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;66;03m# Create and configure environment\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;66;03m##################################\u001b[39;00m\n\u001b[1;32m--> 194\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mOchreEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43menv_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m               \u001b[49m\u001b[43mdefault_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m               \u001b[49m\u001b[43mexp_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mactions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m               \u001b[49m\u001b[43mexp_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvectorize_actions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m               \u001b[49m\u001b[43mexp_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlookahead\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m               \u001b[49m\u001b[43mexp_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreward\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m               \u001b[49m\u001b[43mdefault_args\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdisable_uncontrollable_loads\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m               \u001b[49m\u001b[43mvectorize_observations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvectorize_observations\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m               \u001b[49m\u001b[43muse_all_ochre_observations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muse_all_ochre_observations\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m               \u001b[49m\u001b[43moverride_ochre_observations_with_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moverride_ochre_observations_with_keys\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m               \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;66;03m# Clip Box actions within bounds\u001b[39;00m\n\u001b[0;32m    207\u001b[0m do_clip \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclip_actions\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\ochre-gym-env\\lib\\site-packages\\ochre_gym\\log.py:48\u001b[0m, in \u001b[0;36mredirect_print_statements.<locals>.redirect_print.<locals>.wraps\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwraps\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m RedirectingLogger(logger):\n\u001b[1;32m---> 48\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\ochre-gym-env\\lib\\site-packages\\ochre_gym\\ochre_env.py:130\u001b[0m, in \u001b[0;36mOchreEnv.__init__\u001b[1;34m(self, env_name, dwelling_args, actions, vectorize_actions, lookahead, reward_args, disable_uncontrollable_loads, vectorize_observations, use_all_ochre_observations, override_ochre_observations_with_keys, observation_space_config, logger)\u001b[0m\n\u001b[0;32m    127\u001b[0m lookahead_minutes \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mtimedelta(hours\u001b[38;5;241m=\u001b[39mprice_lookahead\u001b[38;5;241m.\u001b[39mhour,\n\u001b[0;32m    128\u001b[0m                        minutes\u001b[38;5;241m=\u001b[39mprice_lookahead\u001b[38;5;241m.\u001b[39mminute)\u001b[38;5;241m.\u001b[39mseconds \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m60\u001b[39m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lookahead_minutes \u001b[38;5;241m%\u001b[39m time_res_minutes \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    131\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA price lookahead of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(lookahead_minutes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m mins is less than or is \u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[0;32m    132\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m not a multiple of the control interval \u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[0;32m    133\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(time_res_minutes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m mins.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlookahead_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(lookahead_minutes \u001b[38;5;241m/\u001b[39m time_res_minutes)\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m observation_space_config:\n",
      "\u001b[1;31mValueError\u001b[0m: A price lookahead of 15 mins is less than or is  not a multiple of the control interval 30 mins."
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import ochre_gym\n",
    "\n",
    "# 1) Load env with only heating setpoint control\n",
    "env = ochre_gym.load(\n",
    "    \"basic-v0\",\n",
    "    override_equipment_controls={\"HVAC Heating\": [\"Setpoint\"]},\n",
    "    vectorize_actions=True,\n",
    "    vectorize_observations=True,\n",
    "    # Small, stable observation set (edit to taste)\n",
    "    override_ochre_observations_with_keys=[\n",
    "        \"Temperature - Indoor (C)\",\n",
    "        \"Temperature - Outdoor (C)\",\n",
    "        \"Energy Price ($)\",\n",
    "        \"Hour of Day\",           # provided by env if supported; else encode from Datetime in wrapper\n",
    "    ],\n",
    "    start_time=\"2018-12-01 00:00:00\",\n",
    "    end_time=\"2018-12-31 23:30:00\",\n",
    "    time_res=\"00:30\",\n",
    "    dr_type=\"RTP\",\n",
    "    reward_normalization=True,\n",
    "    thermal_comfort_band=[20.0, 23.0],\n",
    "    thermal_comfort_unit_penalty=10.0,\n",
    "    log_to_file=False, log_to_console=False,\n",
    ")\n",
    "\n",
    "# 2) Discretize the heating setpoint (e.g., 7 actions from 20.0 to 23.0 by 0.5C)\n",
    "SETPOINTS = np.round(np.arange(20.0, 23.0 + 0.001, 0.5), 1)  # [20.0, 20.5, ..., 23.0]\n",
    "A = len(SETPOINTS)\n",
    "\n",
    "class HeatingSetpointDiscrete(gym.ActionWrapper):\n",
    "    \"\"\" Map discrete index -> continuous action vector expected by env. \"\"\"\n",
    "    def __init__(self, env, setpoints):\n",
    "        super().__init__(env)\n",
    "        self.setpoints = np.array(setpoints, dtype=np.float32)\n",
    "        # Env expects a vector (because vectorize_actions=True). For heating-only, shape==(1,)\n",
    "        self.action_space = gym.spaces.Discrete(len(self.setpoints))\n",
    "    def action(self, a_idx):\n",
    "        sp = self.setpoints[a_idx]\n",
    "        return np.array([sp], dtype=np.float32)\n",
    "\n",
    "env = HeatingSetpointDiscrete(env, SETPOINTS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eced7f1-b914-41b6-b10f-5dd20248045c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bins per feature (tune these):\n",
    "Tin_bins  = np.arange(18.0, 26.5, 0.5)   # indoor temp\n",
    "Tout_bins = np.arange(-20.0,  45.0, 5.0) # outdoor temp\n",
    "Price_bins= np.array([0.0, 0.1, 0.2, 0.4, 1.0, 5.0])  # price tiers\n",
    "Hour_bins = np.arange(0, 24+1, 3)        # 8 bins over 24h\n",
    "\n",
    "BIN_EDGES = [Tin_bins, Tout_bins, Price_bins, Hour_bins]\n",
    "\n",
    "def discretize(obs_vec):\n",
    "    # obs order matches override_ochre_observations_with_keys\n",
    "    tin, tout, price, hour = obs_vec[0], obs_vec[1], obs_vec[2], obs_vec[3]\n",
    "    vals = [tin, tout, price, hour]\n",
    "    idxs = []\n",
    "    for v, edges in zip(vals, BIN_EDGES):\n",
    "        # np.digitize returns 1..len(edges); convert to 0..len(edges)\n",
    "        i = int(np.digitize(v, edges, right=False))\n",
    "        i = max(0, min(i, len(edges)))  # clamp\n",
    "        idxs.append(i)\n",
    "    return tuple(idxs)  # tuple is hashable => can index Q-table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446488e5-4ff5-4be9-94c5-21879ce55742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Hyperparameters\n",
    "alpha = 0.2        # learning rate\n",
    "gamma = 0.99       # discount\n",
    "eps_start, eps_end, eps_decay = 1.0, 0.05, 20_000  # linear decay over steps\n",
    "episodes = 50\n",
    "max_steps = 2000\n",
    "\n",
    "# Q-table: dict-of-dicts â†’ default 0.0\n",
    "Q = defaultdict(lambda: np.zeros(A, dtype=np.float32))\n",
    "\n",
    "def epsilon(step):\n",
    "    # linear decay\n",
    "    frac = max(0.0, 1.0 - step / eps_decay)\n",
    "    return eps_end + (eps_start - eps_end) * frac\n",
    "\n",
    "global_step = 0\n",
    "\n",
    "for ep in range(episodes):\n",
    "    obs, info = env.reset()\n",
    "    s = discretize(obs)\n",
    "    ep_return = 0.0\n",
    "\n",
    "    for t in range(max_steps):\n",
    "        e = epsilon(global_step)\n",
    "        if np.random.rand() < e:\n",
    "            a = np.random.randint(A)      # explore\n",
    "        else:\n",
    "            a = int(np.argmax(Q[s]))      # exploit\n",
    "\n",
    "        next_obs, r, terminated, truncated, info = env.step(a)\n",
    "        s_next = discretize(next_obs)\n",
    "\n",
    "        # Q-learning update\n",
    "        best_next = np.max(Q[s_next])\n",
    "        td_target = r + gamma * best_next\n",
    "        td_error  = td_target - Q[s][a]\n",
    "        Q[s][a]  += alpha * td_error\n",
    "\n",
    "        s = s_next\n",
    "        ep_return += r\n",
    "        global_step += 1\n",
    "\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "\n",
    "    print(f\"Episode {ep+1:02d} | steps={t+1} | return={ep_return:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e034591-747e-44c1-91df-286a51c8681d",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, info = env.reset()\n",
    "s = discretize(obs)\n",
    "total = 0.0\n",
    "for t in range(2000):\n",
    "    a = int(np.argmax(Q[s]))\n",
    "    obs, r, terminated, truncated, info = env.step(a)\n",
    "    s = discretize(obs)\n",
    "    total += r\n",
    "    if terminated or truncated:\n",
    "        break\n",
    "print(\"Evaluation return:\", total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b0f940-5c20-4320-b17a-f37da670a72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN\n",
    "model = DQN(\"MlpPolicy\", env, learning_rate=1e-4, buffer_size=100_000, verbose=1)\n",
    "model.learn(total_timesteps=400_000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ochre-gym-env)",
   "language": "python",
   "name": "ochre-gym-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
